#!/usr/bin/env bash
set -euo pipefail

# ---- Settings ----
RESOLVE_SPONSORED=true   # Follow sponsored redirect tokens via curl (set false for offline-only)
USER_AGENT="Mozilla/5.0 (compatible; CleanLinkBot/1.0)"  # neutral UA for privacy
CURL_OPTS=(-Ls -o /dev/null -A "$USER_AGENT" -w '%{url_effective}')

if [ "$#" -lt 1 ]; then
  echo "Usage: $0 <facebook-link-or-url>"
  echo "  or: echo URL | $0"
  exit 1
fi

# Read argument (supports stdin too)
if [ "$1" = "-" ]; then
  IFS= read -r input || { echo "No input received"; exit 2; }
else
  input="$*"
fi

# Extract u= parameter
uval=$(printf '%s' "$input" | sed -n 's/.*[?&]u=\([^&]*\).*/\1/p' || true)
if [ -n "$uval" ]; then
  target="$uval"
else
  target="$input"
fi

# URL-decode once
decoded=$(python3 -c "import urllib.parse,sys;print(urllib.parse.unquote(sys.argv[1]))" "$target")

# Decide if the decoded part is a real URL
if [[ "$decoded" =~ ^https?:// ]]; then
  url="$decoded"
else
  if [ "$RESOLVE_SPONSORED" = true ]; then
    url=$(curl "${CURL_OPTS[@]}" "$input" 2>/dev/null || echo "")
    if [ -z "$url" ]; then
      echo -e "\n(Unable to resolve sponsored redirect)"
      exit 0
    fi
  else
    echo -e "\n(Facebook sponsored redirect â€” cannot decode offline)"
    exit 0
  fi
fi

# Clean URL
clean=$(python3 - "$url" <<'PYCODE'
import sys, urllib.parse as u, re

decoded = sys.argv[1]
parts = u.urlparse(decoded)
qs = u.parse_qsl(parts.query, keep_blank_values=True)

# --- Remove common tracking parameters ---
bad_params = {
    'fbclid','utm_source','utm_medium','utm_campaign','utm_term','utm_content',
    'ref','ref_src','ref_url','gclid','yclid','mc_cid','mc_eid','icid',
    'sr_share','mkt_tok','pk_campaign','pk_kwd','trackingid','trk','cmpid'
}
filtered = [(k,v) for (k,v) in qs if k.lower() not in bad_params]

new_query = u.urlencode(filtered, doseq=True)
new_url = u.urlunparse((parts.scheme, parts.netloc, parts.path, parts.params, new_query, parts.fragment))

# --- Trim after web extensions ---
exts = ['html','htm','php','asp','aspx','jsp','jspx','shtml','cgi','pl','rss','xml','json']
pattern = r'(?i)(\.(?:' + '|'.join(re.escape(e) for e in exts) + r'))\b.*'
cleaned = re.sub(pattern, r'\1', new_url, count=1)

print('\n'+cleaned)
PYCODE
)

echo "$clean"

